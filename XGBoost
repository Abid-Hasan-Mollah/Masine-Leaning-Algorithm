import xgboost as xgb

# Convert your DataFrame to DMatrix, which is the internal data structure used by XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Define parameters for XGBoost classifier
params = {
    'objective': 'binary:logistic',  # for binary classification
    'eval_metric': 'error'  # evaluation metric
}

# Train the XGBoost classifier
num_rounds = 100  # You can adjust the number of boosting rounds
bst = xgb.train(params, dtrain, num_rounds)

# Make predictions
y_pred_prob = bst.predict(dtest)
y_pred = [1 if x > 0.5 else 0 for x in y_pred_prob]

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
